========================================================================================================================================================
==================================================               IMP POINTS              ===============================================================
========================================================================================================================================================

1)Before creating ec2 instance/VM for any OS port opening should be done first for ssh otherwise u will get connection timed out error.
STEPS for creation of port :- security groups --> inbound rules --> add port and allow any ipv4 address
Linux ssh :- 22 port 
windows :-3389 -->u will get username and pass as well from which you should connect it

one key pair can connect multiple servers/ec2 consoles.

2) EBS --> 2 TYPES --> root and additional
Note :- root volume for linux bydefault is 8 gb and for windows it is 30 gb 

3) for zones & regions :- 
to see zones  :- ec2 --> settings --> u will see list of zones for particular region 
eg:- Asia Pacific(mumbai) region ---> zones are ap-south-1a,ap-south-1b,ap-south-1c
Note :- 
if u are using services of zone A then dont use services of other zones or regions 
but in snapshots u can do it :- in snapshot we can create a backup of zone A Region Mumbai into Zone B Region Hyderabad 

4) round robin means 1st request will go to flight 1 2nd will go to flight 2  and again flight 1 instance

5) for IAM custom policy steps . :- 38:54:-  IAM 
create user groups --> create user and add that user into that group 
create role and add that role to 

6) AWS CLI imp. :- 26:56 wala lec- ( AWS CLI) 

7)
For programatically login into awa cli/ java /terraform u need to do it with secret key and access. Key:- 
Search iam --> create user --> 3 options (attach policy directly) -->user created successfully.
 after creation go to users --> select one user --> create access key and private key
Note:- can create access key for root as well but it is not recommended to do so 

IAM user :- username :- test-user password :- test@pvk

Note :- 
IAM we can directly create and attach a policy to user 
create a policy and attach to user group and attach it to user 

8)# AWS Networking Quick Notes

## A. Internet Gateway (IGW)
- Connects VPC to the **internet**.  
- Used by **public subnets / EC2 with public IP**.  
- Allows **inbound + outbound** traffic (if SG permits).  
- Route example: `0.0.0.0/0 → igw-xxxx`

---

## B. NAT Gateway
- Used by **private subnets (no public IP)**.  
- Allows **only outbound** internet access (e.g., updates, API calls).  
- **Blocks inbound** traffic from the internet.  
- Private EC2 → NAT (in public subnet) → Internet.  
- Route example: `0.0.0.0/0 → nat-xxxx`

---

## C. Difference: IGW vs NAT

| Feature        | Internet Gateway | NAT Gateway |
|----------      |------------------|--------------|
| Used for       | Public EC2       | Private EC2 |
| Inbound        | ✅ Allowed       | ❌ Blocked |
| Outbound       | ✅ Allowed       | ✅ Allowed |
| Public IPneeded| Yes              | No          |
| Typical use    | Host website     | Download packages securely |

---

## D. Security Group vs IGW
- **Security Group** = Permission (who can go in/out).  
- **IGW** = Internet connection (actual door).  
- Both needed: SG allows it, IGW provides the path.

---

## E. API Gateway
- Public entry point for your **backend APIs**.  
- Can connect to **Lambda**, **EC2**, or **internal services**.  
- Adds **security**, **authentication**, and **rate limiting**.  
- Used to expose **private EC2s** safely to the internet.




========================================================================================================================================================
========================================================================================================================================================

☁️ Cloud Service Models
Cloud providers offer different levels of services depending on how much control and responsibility you want. These models are:

IaaS – Infrastructure as a Service
PaaS – Platform as a Service
SaaS – Software as a Service


🧱 What is IaaS (Infrastructure as a Service)?
####################################################
-> IaaS is a cloud service model where the cloud provider gives you raw infrastructure, and you build everything on top of it.

🏗️ Think of it like:
"You rent a fully functional empty building, and it’s your job to furnish it, decorate it, and use it however you want."

✅ What the cloud provider gives you:
---------------------------------------------
🖥️ Virtual Machines (VMs)
🌐 Networking (IP, firewall, load balancer)
💾 Storage (hard drives, SSDs)
⚙️ Virtualization, Servers, Data Center

✅ What you (the customer) have to do:
------------------------------------------------
Install Operating System (e.g., Ubuntu, Windows)
Install runtime environments (Java, Python, Node.js, etc.)
Set up web servers (Apache, Nginx, Tomcat, etc.)
Deploy and manage your application code
Handle updates, patches, and security

📦 Example Scenario
----------------------------------
Let’s say you want to host a Java web application.

Using IaaS:
------------
You create a VM on AWS EC2
Install Ubuntu
Install Java, Tomcat, MySQL
Deploy your .war file
Configure your firewall, ports, etc.

🔧 Common IaaS Providers
Provider	     	Service Example
AWS			          EC2, EBS, VPC
Microsoft Azure		Virtual Machines
Google Cloud		Compute Engine
Oracle Cloud		OCI Compute
DigitalOcean		Droplets

------------------------------------------------------------------------------------------------

⚙️ What is PaaS (Platform as a Service)?
#############################################
PaaS is a cloud service model where the cloud provider gives you a ready-made platform (runtime, OS, web server, etc.) so that you can directly deploy and run your application — without worrying about setting up servers or infrastructure.

🎯 Key Idea:
You focus only on developing and deploying your code, and the cloud provider takes care of the platform and infrastructure underneath.

✅ What the cloud provider gives you:
----------------------------------------
Pre-installed OS
Runtime environment (like Java, Node.js, Python)
Web server (e.g., Apache, Tomcat)
Auto-scaling, load balancing, and patching
Built-in monitoring and logging

✅ What you (the customer) need to do:
----------------------------------------
Write your application code
Upload/deploy your app on the platform
Manage your data, and maybe configure some settings

You don’t need to:

Install OS
Set up web servers
Configure runtime manually

📦 Example Scenario
------------------------
Let’s say you want to deploy a Java Spring Boot application.

Using PaaS:

Choose a PaaS provider like Heroku or Google App Engine
Push your code using Git

The platform automatically:

Sets up the Java environment
Deploys your app
Manages scaling and traffic
You just monitor it and update the code when needed.

☁️ Popular PaaS Providers
Provider				          Service Example
Heroku				          Easy app deployment (multi-language)
Google App Engine		    Run apps without managing servers
AWS Elastic Beanstalk		Deploy web apps in Java, .NET, PHP, etc.
Microsoft Azure App     Service	Deploy and scale web apps easily

-----------------------------------------------------------------------------------------------------

💻 What is SaaS (Software as a Service)?
####################################################
SaaS is a cloud service model where the cloud provider gives you ready-to-use software, and you can access it through the internet — no installation, no setup, no servers.

🎯 Key Idea:
You simply use the software; everything else — like servers, updates, backups, and security — is managed by the cloud provider.

✅ What the cloud provider handles:
------------------------------------------
Application software
Servers and infrastructure
Updates and bug fixes
Data storage and backup

Security and availability

✅ What you (the customer) do:
--------------------------------------------
Just log in to the app (usually in a browser)

Use it to manage your tasks, documents, communication, etc.

Pay monthly/yearly (subscription)

📌 No need to install, manage, or update anything.

📦 Example SaaS Applications
App				            	Purpose
Zoom				          Video meetings and communication
Google Drive / Docs		File storage, editing, collaboration
Dropbox	Cloud 			  storage
Microsoft 365 (Teams, Word)	Productivity & collaboration
Jira				          Project management & issue tracking
Salesforce			      Customer relationship management (CRM)


<=======================================  AWS ============================================> 
SUMMARY

A) EC2 (Elastic Compute Cloud) ====>
Virtual servers in the cloud.
Scalable computing capacity.
Users can provision, manage, and terminate instances as needed.

1. AMI (Amazon Machine Image)
A template used to create EC2 instances.
Includes OS, applications, and settings.

2. Key Pair
A secure way to access EC2 instances.
Consists of a public key (stored by AWS) and a private key (kept by the user).
used to connect local system to ec2 server/instances

3. Security Groups
-Virtual firewalls that control inbound and outbound traffic for EC2 instances.
-can restrict which urls will be allowed and which would be restricted

4. EBS :- Elastic Block Store
-Durable block storage for EC2 instances.
-can increase volume once storage gets exceeded
-snapshots ==> immediate copies 

5.loadbalancer :-

6.Autoscaling :-
-Automatically adjusts the number of EC2 instances in response to demand.
--for eg :- in flipkart,autoscaling increases size of server to 1000 during sales time and reduces size of server to 100/200 after sale gets end.

B) s3 :- for storage --> images,video, 

C) RDS :- for mysql,PostgreSQL database

D) Dynamo DB :- for NoSQL database
   Document db :- mongodb

   cloud9 :- ide for coding and debuggin

E) IAM ( Identtity & Access management ):- 
- create subaccounts with restrictions for users .
- users will have limited access to permitted services
--Manages users and their permissions to AWS resources securely.

iam , vpc , elastic beanstalk, cloud watch, sns , aws lambdas, efs ecs , eks , routes3 , cloud front

F) vpc( virtual private cloud) :-
same as IP address
Like your own little network with walls—you decide who gets in and out.

🔐 Example: You run sensitive apps inside a VPC so the public can’t access them directly.

G) elastic beanstalk:- (PAAS) 
-use to automate the process like ec2 all configurations will be done
-- billing will be continuos even if you are not using app at night. 
=You just give your code (e.g., a Python or Java app), and Elastic Beanstalk sets everything up—servers, storage, scaling—for you.
- aws beanstalk is free of charge but the resources inside beanstalk you are using you will get charged for that. Resources like :- ec2, s3 , rds ,...

🧑‍🍳 Example: You upload your website code, and it runs on the internet without you touching servers.


F) aws lambda:- 
- similar to elasticbeanstalk but one advantage here is how much usage your service is doing only that much you have to pay
- here, it is pay as you use ; for eg: - how much request you get in your server that much billling will be generated

for eg:- if no one visits your website then also beanstalk will charge you on hourly basis but here if no one visits or no requests got hit then no service will get charge.

G) cloudwatch :- 
- if servers load get 90-95 % it will give alert to admin of app /user 
--used for monitoring purpose 
-Monitoring service for AWS resources and applications, offering logging and alerts.
📊 Example: Your website gets super slow—CloudWatch can alert you and show why.

H) SNS (Simple Notification Service) :-
-Pub/sub messaging service for sending notifications and messages between services.


🗂️ EC2 Instance Instance types :-  (with Details)
Code	Meaning & Use Case
t	=>Burstable performance – Low-cost, good for light workloads like dev/test, blogs, small apps
m =>	General purpose / Balanced – Good mix of CPU, memory, and network for web servers, app servers, small to mid-size DBs
r / x / u	 => Memory-optimized – Best for large in-memory workloads, high-performance databases (PostgreSQL, SAP HANA, Redis), analytics
c	 =>Compute-optimized – Ideal for CPU-bound tasks like batch processing, high-performance web apps, gaming, ML inference
g / p / inf	=>Accelerated / GPU-based – Best for ML training (p), inference (inf), video rendering or graphics (g)
i / d	=> Storage-optimized – Designed for fast SSD (NVMe) or large HDD use cases like NoSQL DBs, data lakes, logs, streaming apps
hpc =>	High-performance computing – Built for tightly-coupled simulations, modeling, scientific computing, CFD, etc.
z	=> High clock speed instances – For workloads that need high per-core performance (e.g., EDA tools, financial modeling, software licensing-based apps)


==================================================================================================================

NOTE: - 

EC2 :---->
Images = AMI , AMI catalog
Elastic Block Storage = volumes , snapshots , lifecycle manager
Network & security = Security groups, Elastic IPs , Placement groups , Key Pairs , Network interfacesload
Load balancing = load balancers , Target groups, Trust stores
Auto scaling = Auto scaling groups

VPC :--> 
Your VPCs
Subnets
Route tables
Internet gateways
Egress-only internet gateways
Carrier gateways
DHCP option sets
Elastic IPs
Managed prefix lists
NAT gateways
Peering connections
Route servers

Practical 

----------------------------------------
2ND LEC
1) 
Before creating ec2 instance/VM for any OS port opening should be done first for ssh otherwise u will get connection timed out error.
STEPS for creation of port :- security groups --> inbound rules --> add port and allow any ipv4 address
Linux ssh :- 22 port 
windows :-3389 -->u will get username and pass as well from which you should connect it

one key pair can connect multiple servers/ec2 consoles.

2) Every server/vm has 2 ips :- private and public
pubilc IP gets changes every time server gets restart so to avoid this use "elastic IP" 
STEPS :- 
below security groups --> Elastic ip -->
Associate the instance in elastic ip so you will see now public ip will remain static now


3) Region and zone :- // can see region*Asia pacific(mumbai) in top of aws and zone in ec2 console alongside status u willl see availability zone :- 
ap-south-1a
ap-south-1b
ap-south-1c

region is like city and zone is address or buildings
Note :- if you are using service of one zone so dont use another zone for other service 
for eg:- if your server is in building a(zone) if if you are using service ebs of building b (zone b) not possible.

4)Types of EBS -->  //Attach the additional volumes to your instance 

2 Types of EBS:-  Root volumen and additional volume 
Note :- root volume for linux bydefault is 8 gb and for windows it is 30 gb 

✅ 1) General Purpose SSD (gp3 / gp2)
Min: 1 GiB
Max: 16,384 GiB (16 TB)
Use Case: Best for everyday use, such as running your OS, boot volumes, and general workloads.

💡 Good for:
Web servers
Small to medium databases
Development and testing environments

📌 gp3 is newer and offers better performance at a lower cost compared to gp2.

✅ 2) Provisioned IOPS SSD (io1 / io2)
io1: Min 4 GiB, Max 16,384 GiB
io2: Min 4 GiB, Max 65,536 GiB (65 TB)
Use Case: Best for high-performance databases and applications that need consistent and fast I/O.

💡 Good for:
Mission-critical databases (like Oracle, SQL Server, PostgreSQL)
High-performance workloads (financial systems, analytics, etc.)

🔧 You can provision the number of IOPS (input/output operations per second) for predictable performance.

✅ 3) Cold HDD (sc1)
Min: 125 GiB
Max: 16,384 GiB
Use Case: Designed for infrequently accessed data.

💡 Good for:
Backup storage
Archival storage
Large volumes of rarely accessed files

✅ 4) Throughput Optimized HDD (st1)
Min: 125 GiB
Max: 16,384 GiB
Use Case: Ideal for large, sequential workloads.

💡 Good for:
Big data
Data warehouses
Streaming log data
Large-scale file systems

📊 Focus is on throughput (MB/s), not IOPS.

✅ 5) Magnetic (Standard) (legacy, rarely used now)
Min: 1 GiB
Max: 1,024 GiB (1 TB)
Use Case: Old-generation storage type. Mostly used in the past for low-cost workloads.

💡 Good for:
Small, infrequent workloads
Archival (only if legacy reasons force it)

4) 1:06:48 (ebs additional storage) : -

ebs additional storage can be added of same zone and same region 

5) 44:00 :-->(snapshot) :- Backup of an EBS volume.  (immediate backup ) 

-We can create snapshot from one region to other region or one zone to other zone
- u can create a snapshot from volume and then create volume from snapshot 
NOte: Volume  ➝  Snapshot  ➝  Volume
-can schedule daily for backup and can keep only last 10 days backup restall will be deleted

EG:- 
in snapshot we can create a backup of zone A Region Mumbai into Zone B Region Hyderabad 

1:06:48 ::: ebs additional storage adding and removing (mount /demount)

6) LB :-  54:44 --> LB 

- first create target group and add instances in target group
- while creating instance in advance option run shell command given in psa notes so it will run automatically once instance is been created.
- consider if u have microservices architecture  

ALB --> Target group 1 --> 2/3/... instances [flight 1,2,3,...]  
 |-----> Target group 2 --> 2/3/... instances [hotel 1,2,3,....]
 
 Note :-   ;;;;; round robin happens here like eg:- 1st request will go to flight 1 2nd will go to flight 2       
 |            then flight 3 then again flight 1 ......  likewise traffic is distributed


7) 32:16 --> auto scaling ( create launch template first which comes under instances)

Can create own AMI as well which will contains preconfigured or predefined softwares.
Instances --> actions --> create image -->
After creation :-
While creating instance in my AMIs your image will be visible there so select it

8) 27:16:- RDS 
2 options public access :- yes or no
Yes :- then we can access database locally from our workbench but it is not recommended for our production application as anyone can have public access.

No :- use VPC here 
Vpc is like network which helps our ec2 and database gets interconnected to reach other.

Note :- Security groups acts as firewall

After creating database in RDS --> settings in firewall as well 3306 port open --> workbench copy dns from Rds and paste in workbench new connection --> hostname (earlier it will be 127.0.0.../localhost) ,username and password which u set in RDS during creation --> you are connected now

9)42:50:- S3 services:-

Used for storing any type of files like PDF, Excel sheet, images, audio , videos
NOTE:-But per file size should not exceed above 5TB

-S3 Bucket name should be unique
-Inside one bucket files are stored which are called as objects
-While creating bucket there will be option of. ACL ( enable or disable) if disable then object access is not possible through url so keep it enabled to get access of file/image after hitting url

Versioning :- if u enabled versioning and try to upload any object abc.png then if u again upload abc.png it will not override previous one ; we can see both abc.png file out there

10) 36:54:-- Transfer acceleration

Once bucket created --> properties --> transfer acceleration --> enable 

21 se IAM role in AWS:-- we can give limited access to particular user

For programatically login into awa cli/ java /terraform u need to do it with secret key and access. Key:- 
Search iam --> create user --> 3 options (attach policy directly) -->user created successfully.
 after creation go to users --> select one user --> create access key and private key
Note:- can create access key for root as well but it is not recommended to do so 


11)38:54:-  IAM  -->
Access Management :- 
User groups ,Users , Roles , Policies , Identity Providers, Account settings ,Root access management

STEPS TO CREATE USER GROUP :- 

i)
create user group :- 
for developers , devops, TL , everyone has other types of access so create user groups 

for devops :- select poilcy --> AdministratorAccess (Full AWS services access)

devops group created!!

ii)
create user --> add user details --> set permissions ( 3 options : Add user to group  / copy permissions / Attach policies directly) -->
select Add user to group --> select group --> devops 

----------
ROLES:- 
-For interacting EC2 with EKS we dont need policies to select instead roles should be created here
- Restriciting ec2 instance with which services it can access.
- AWS services interacting with any other services.

STEPS for role creation:- 

i) select trusted entity --> AWS service(multiple options present) & use case --> EC2 (multiple options present) -->
ii) Add permissions --> AmazonEKSServicePolicy (multiple options present like AdministratorAccess,amazonRDS,..)
iii) Name,review and create --> Name of role -->

Role created succesfully !!

---------------
POLICIES :- (custom policies can be created ) 
eg :- if we want to give region specific service like S3 service should be used with specific region mumbai ap south 1

STEPS :-  (before creating policy for s3 bucket one bucket should be created 

create policy --> 2 types ( visual/JSON) --> select JSON -->  choose service --> s3 full and select bucket as well  --> now select condition and add above mumabi ap south 1 --> JSON will be created 

Policy created succesfully !!

Now into user --> attach above policy --> so now user will be able to access only s3 bucket 

12) 26:56 wala lec- ( AWS CLI) 

we are using UI of aws but UI keeps changing so sometimes it becomes difficult to find something so AWS cli comes into picture
u just need to use commands in CLI for using any particular service and that's it
Note : -search AWS CLI documentation. :- docs.aws.amazon.com/cli/

STEPS ::-
go to profile --> security credentials --> create access key and secret key ( as this will be for root user ) 

download AWS cli --> see documentation where u will get commands --> after downloading install it 

Login steps and usage of AWS cli :- 
--> open cmd as administrator -->  
check command :-
i) aws --version 
ii) aws configure  --> add access key , secret key , region( ap-south-1) , output format :- (JSON) 
iii)aws s3 mb s3://bucket-name   //for bucket creation 
    aws s3 ls  //to see list of buckets
iv) cls //for clear screen


13) 46:00 :: cloud watch and Sns and revision from 30 .

For SNS --> create topic --> create subscription --> add email ID 

Create ec2 instance --> select action --> monitor and troubleshoot --> manage cloud watch alarm

14) 44:20 :: Elastic Bean stalk

-EBS is PAAS 
-U will get platform u just need to deploy code
-Ebs reduces load of adding rds,vpc, security group,autoscaling,ec2 instance....
 
15) 1:05:56 :: Elastic bean stalk continue practical above also

-IAM role create policies and add as mentioned in above lec.
-While creating we will require policies and attach it into beanstalk

9:55 se dekh

vpc concept explained with ip addresses as well

VPC: In AWS (Amazon Web Services), VPC stands for Virtual Private Cloud.
-----------------------------------------------------------------------
a. Amazon VPC is a logically isolated virtual network that you create in the AWS cloud. It is your own private network space in AWS
b. Your VPC is like your own private data center within AWS.
c. No other company can see or access your resources — unless you explicitly allow it.
d. VPC is a free Service in AWS

16) 1:10:08 ::

VPC:-
-isolated network
-vpc sizing :- how many ip range needed (CIDR)

CIDR --> defining reserved IP addressses
subnets (sub networks) --> dividing large network into small networks (subnets has CIDR ranges) 

why subnet ?
-->
to control traffic 
for eg:- subnet 1 resources to keep private and subnet 2 to make public
subnet 1 contains rds subnet 2 contains app  which is public 

Note:- 
-bydefault one vpc is created in aws  for eg:- 172.31.0.0/16 --> 65,536 ips (2^16)
- 3 subnets by default --> 
for eg:- 172.31.16.0/20 --> 2^12 --> 4096 but showing 4091 available in aws coz 5 ips used by aws for internal purpose 
2 more are there ..


18:45 se dekhna hain
==================================================================

VPC:-
-isolated network
-vpc sizing :- how many ip range needed (CIDR)

CIDR --> defining reserved IP addressses
subnets (sub networks) --> dividing large network into small networks (subnets has CIDR ranges) 


🌐 What is a Subnet?
--------------------------------
-A subnet (short for subnetwork) is a smaller network segment created by dividing a larger network (like a VPC) into multiple, logically separated pieces.
-To define which resources should be accessible privately and which to be accessed publically 
reources :-- rds,ec2,s3,....

why subnet ? 27:00 diagram copy 
-->
to control traffic 
for eg:- subnet 1 resources to keep private and subnet 2 to make public
subnet 1 contains rds subnet 2 contains app  which is public 

Note for AWS subnet breakdown:- 
-bydefault one vpc is created in aws  for eg:- 172.31.0.0/16 --> 65,536 ips (2^16)
- 3 subnets by default --> 
for eg:- 
172.31.16.0/20 --> 2^12 --> 4096 but showing 4091 available in aws coz 5 ips used by aws for internal purpose 
172.32.16.0/20 --> 2^12 --> 4096
172.33.16.0/20 --> 2^12 --> 4096

Route Table --> while u click subnet u will see route table section out there 
-communication between one subnet to other subnet is being done by route table
-Each subnet must be associated with a route table. However, traffic within the same subnet does not require routing via the route table—instances communicate directly. 
-Route tables are used to route traffic between subnets within a VPC, between VPCs, and from subnets to outside networks

Internet gateway -->
-it defines whether subnet is private or public 
-An Internet Gateway (IGW) is a VPC component that allows communication between your VPC and the internet.
-Send traffic to the internet
-Receive traffic from the internet
eg :- 
in route table section if IG is attached then subnet is public so it can be accessible within VPC and outside VPC as well 
whereas if IG is not attached then subnet is private subnet and can make communication within VPC only

NAT gateway :- 
-NAT Gateway stands for Network Address Translation Gateway.
-It allows instances in a private subnet to access the internet, but prevents the internet from initiating connections back to those instances.
for eg:- 
in private subnet rds is there and if we want to update rds latest version which is available online but due to private subnet we dont have access
to internet so NAT helps to download the updates by sending request from private subnet to website and downloading the updates but it cannot take
the response from client side like we can send requests only.


17)44:06 :- 	PRACTICAL FULL VPC creation

nOTES :-
- ONE route table can connect to multiple subnets 
- after your work, do delete your custom vpc so it will close IG,RT,subnet, ec2 so you dont need to close everything manually 

steps :- 

a) create VPC :- assign CIDR ranges --> VPC created along with default ROute tables. (private-default-pvk)

b)
create vpc 0/16 (65k IPs) ----> create 2 more Route tables (private RT and public RT )  
--> 2 subnets (private subnet and public subnet ) and attach route tables which created in previous step 
-->  create Internet gateway and in actions attach it to your VPC
-->  Now in public RT go to route section and add route --> 0.0.0.0/0 and add internet gateway which you created
Note :- while adding route these are called as targets (IG /NAT/ Any IPs)

Now while creating new EC2 instance --> during network settings --> add custom vpc which we created and attach public subnet as well bcoz of this we can connect using ssh on local system 
Note :- AUto assign public IP --> ENable during network settings --> edit network settings and auto assign --> created 2 instance one is private and public 
--> in security group of ec2 --> inbound rule add type --> ssh --> port 22 --> source  (0.0.0.0/0)
O/P :- public gates connected through ssh but private don't

for public vm --> ping google.com
u can see in networking section of vm-public --> private dns ip:- 10.0.0.144

IGW + Route Table = road to internet.
Security Group Inbound Rule = gate to your house (you must open it for SSH).

18) 43:44 :- peering of vpc practical

🔹 VPC Peering (Virtual Private Cloud Peering)

VPC Peering is a networking connection between two VPCs (Virtual Private Clouds) that enables them to communicate privately as if they were on the same network.

use peering connection 	
	`
Practical :- ec2 instance of default vm of one vpc should connect with custom vm present in other vpc   

ec2-vpc1-vm(default) should communicate with ec2-vpc2-vm (custom created) 
OUTPUT :- use ping command to check connectivity :- ping 10.0.0.14(custom ec2-vpc2-vm) 

vpc-1 default range ==> 172.0.0.0/16
vpc-2 range ==> 10.0.0.0/16

edit in security group as well

Note :- 
Security groups are protecting our resources in ec2 instance 
vpc is protecting our subnets 
route table is protecting the subnets 	
																													

19) 41:26 :-  EFS (Elastic File System) 

starting Network ACL little bit

s3 vs  EFS :- 

s3 -->
-use whenever u are using apis to upload or download file/videos
-returns URLs to access it 
-used for Large files
- Billing is effective compared to EFS

EFS -->
-can be used as shared file system bcoz we are sharing files from one instance to another instance eg: -  in EFS ,same config file is used in VM-1 and VM-2 if some file/video changes in VM-1 then it will reflect in VM-2 as well 
- very costly for large file so prefer s3 for large files.


practical :- create 2 instances A and  B so if any file is upload or modified in A then will reflect in B also

create 2 instance -->intall efs in both instance  ->
port open for 2049 in security goup -->

20) 22:08 :--- cloud formation

In template 3 options are there :- 
Git, local upload and aws s3 url like upload yaml in s3 bucket and provide url

Search from chatgpt:- Ec2 creation using yaml file 
Note :- while saving from notepad save as 
"Infra.yaml" otherwise it will save as .txt file instead of .yaml


-------------------------

21) 32:52 :: Terraform

Install Terraform for windows 
Add .exe path in system variable

Steps :- in 43 architecture is there

-in vs code create main.tf file for terraform
-now for connecting cloud services like aws/google cloud first define provider block
Note:- search in cpt provider block+ secret key + access key for aws --> Define IAM user as well and create role with admin access permissions --> will get access key and secret key
- after writing code/hcl type below commands:- 
*Terraform init // for installing packages written inside provider block and generates terraform.lock.hcl file which contains plugins details
*Terraform validate // for validating configurations
*Terraform fmt // for recorrecting format /indentations
*Terraform plan //generates plan document
Which contains project details stored in form of json inside terraform.hcl file
*Terraform apply // generates JSON structure and genrates resources in aws

28 :::

Create a folder for each env uat,dev,prod
In uat create provider.tf,.... 
In prod same
To access in terminal :-
Right click to folder(uat) --> open in integrated terminal --> start typing commands

Create input variable for passing values for Ami , instance type, ...


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
PRACTICAL ---------------------------------------------------------------------------
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Custom AMI creation ::- --
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

1)Launch EC2 instance → choose any base AMI (Ubuntu, Amazon Linux, Windows). use security group :- launch wizard which is created by me (8080,8090,80 port present )
2)Install & configure software you need (Java, MySQL, Nginx, etc.).
3)In EC2 console → select instance → Actions → Image → Create Image.
4)Give name + description → click Create.
5)AWS will create your custom AMI (visible under AMIs in EC2  --> in MY AMIs).
Now you can launch new EC2s using this AMI.

* java and nginx creation steps :-  (port of 80 should be opened  :- type :- HTTP protocol:-TCP port range:-80) 

kp --> praj_kp (present in c drive) 
instance type -> t3.micro

sudo yum install -y java-17-amazon-corretto
sudo yum install -y nginx

command to check java and nginx :-->
java -version
systemctl status nginx

To start nginx :- 
sudo systemctl enable nginx
sudo systemctl daemon-reload
sudo systemctl restart nginx
sudo systemctl status nginx

To see which port nginx is listening ?
-->
netstat -tulpn | grep nginx 
t → TCP connections
u → UDP connections
l → Listening ports (services waiting for connections)
p → Show the process name / PID using the port
n → Show numeric addresses/ports (instead of hostnames/service names)

Check url on browser :-  //u will se Welcome to nginx! page
http://13.203.221.193/

Note :- ssh -i "praj_kp.pem" ec2-user@ec2-43-204-228-173.ap-south-1.compute.amazonaws.com  //login with ec2-user instead of root 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Additional Volume Creation ::- --
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

🔹 Create EBS Volume

1)Go to EC2 Console → Elastic Block Store → Volumes.
Click Create volume.

2)Choose:
Size (e.g., 10 GB).
Volume type (gp3/gp2 for general purpose).
Availability Zone (AZ) → must match the EC2 instance’s AZ. (if zone is ap-south-1b in ec2 then while creating volume also select same only)
Click Create volume.

3)Attach Volume to ec2 Instance :- 
On volumes section --> Select the created volume → Actions → Attach volume.  --> Choose your EC2 instance.

It gets attached as a device (e.g., /dev/sdf or /dev/xvdf).

4) Inside ec2 instance when u type df -kh u will not see additional volume as u need to mount it using below commands :- 

i>To Verify if the volume is attached -->
lsblk  //This will list all block devices.

You should see something like:

nvme0n1   8:0    0    8G  0 disk
├─nvme0n1p1
└─nvme0n1p128
nvme1n1   8:16   0   10G  0 disk   <-- your new volume

ii> Create a filesystem on the new volume (only first time!)
sudo mkfs -t xfs /dev/nvme1n1
where ,
sudo mkfs -t xfs /dev/nvme1n1
sudo         → run as root (needs admin rights).
mkfs         → “make file system” (formats the disk so Linux can use it).
-t xfs       → type of filesystem = XFS (you could also use ext4).
/dev/nvme1n1 → the raw new disk (your 10GB volume).

👉 In short:
This command formats your new empty disk with XFS filesystem, so you can later mount and store files in it.

iii>Make a mount point
sudo mkdir /data

iv> Mount the volume
sudo mount /dev/nvme1n1 /data

v> Verify
df -kh
Now you should see your 10GB volume mounted at /data.

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
VPC CREATION ::- --
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Note :- The CIDR block size must have a size between /16 and /28.

1)VPC creation
create vpc -->IPv4 CIDR block = select(IPv4 CIDR manual input) --> IPv4 CIDR =give range (10.0.0.0/16 ) --> IPv6 CIDR block = No IPv6 CIDR block -->

2)create route table and internet gateway as well :-
create vpc 0/16 (65k IPs) ----> create 2 more Route tables (private RT and public RT )  
--> 2 subnets (private subnet and public subnet ) and attach route tables which created in previous step 
-->  create Internet gateway and in actions attach it to your VPC
-->  Now in public RT go to route section and add route --> 0.0.0.0/0 and add internet gateway which you created
Note :- while adding route these are called as targets (IG /NAT/ Any IPs)

3) subnet :- 
create subnet --> choose vpc --> subnet created 
for private subnet keep setting as it is but for public subnet if you want to create then :- 
choose subnet --> actions --> Enable auto-assign public IPv4 address (tick it) 
Note :- for private no need to enable auto assign

4) EC2 insstance :- 

Now while creating new EC2 instance --> during network settings --> add custom vpc which we created and attach public subnet as well bcoz of this we can connect using ssh on local system 
Note :- AUto assign public IP --> ENable during network settings --> edit network settings and auto assign --> created 2 instance one is private and public 
--> in security group of ec2 --> inbound rule add type --> ssh --> port 22 --> source  (0.0.0.0/0)
O/P :- public gates connected through ssh but private don't

private vm :-10.0.1.109
public vm :- 10.0.0.141

as private subnet is useful for rds so created rds using private subnet :- it requires subnet in diff availablity zone then only it will create otherwise not
eg :- 
Name:   database-1.cjy20ce6uzqs.us-east-1.rds.amazonaws.com  //dns of sql rds
Address: 10.0.2.248

5) connect RDS using public ec2 instance but rds is inside private subnet :- 

after creating database --> actions --> connect to ec2

commands for ec2==>

✅ Install MySQL Client on Amazon Linux 2023
sudo dnf install mariadb105 -y

👉 Even though the name says mariadb105, it actually provides the mysql client command (mysql CLI tool).

🔹 Verify Installation
mysql --version

You should see something like:
mysql Ver 15.1 Distrib 10.5.16-MariaDB ...

🔹 Connect to RDS
mysql -h <RDS-ENDPOINT> -u <username> -p

Note :- see vpc dashboard and delte all which are created 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
IAM usage ::- --
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Q1 .Create an IAM User with giving s3 readonly policy to that user

users  --> create user --> create password automatically 

4 steps while creation:- 
1)specify user details
2)set permissions  :- ( 3 options :- Add user to group ,Copy permissions,Attach policies directly)
used last option and added "AmazonS3ReadOnlyAccess" policy  
3)review and create :- AmazonS3ReadOnlyAccess & IAMUserChangePassword (2 policies attached here )
4)retrieve password :- //u will see url and poassword here

Console sign-in URL :
https://637423187767.signin.aws.amazon.com/console

User name : test-user
Console password :xO8@2m)t

//
after creation click url and sign in and use old pass and create new pass using special char caps ,...

once login u can see only buckets which are created already but dont have access to create new one or any other services

Q2.Custom Inline Policy

Write an inline JSON policy that allows:
Full access(read/write) to one specific S3 bucket (e.g., pvk123).
Deny access to all other S3 buckets. 
Attach it to test-user.
soln:-

IAM --> policies --> create policy --> (2 types visual/JSON) --> choose json and select what u want to add and create policies

json select service --> s3 --> now select -> ListBucket --> add resource --> select resource type --> define bucket name /object name here 
will generate JSON !!!

JSON :- 
{
	"Version": "2012-10-17",
	"Statement": [
		{
			"Sid": "Onlypvk123bucketpermission",
			"Effect": "Allow",
			"Action": [
				"s3:ListBucket"
			],
			"Resource": [
				"arn:aws:s3:::pvk123"
			]
		},
		{
			"Sid": "modificationObjectPermissions",
			"Effect": "Allow",
			"Action": [
				"s3:GetObject",
				"s3:PutObject",
				"s3:DeleteObject"
			],
			"Resource": [
				"arn:aws:s3:::pvk123/*"
			]
		},
		{
			"Sid": "listingAllBuckets",
			"Effect": "Allow",
			"Action": [
				"s3:ListAllMyBuckets"
			],
			"Resource": [
				"*"
			]
		}
	]
}

where,
Statement 1 → lets them see bucket list.
Statement 2 → lets them list objects in pvk123.
Statement 3 → lets them work with objects.


